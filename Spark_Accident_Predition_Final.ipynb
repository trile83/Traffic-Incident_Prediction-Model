{"cells":[{"cell_type":"code","source":["sc"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.172.237.64:47080\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        "]}}],"execution_count":1},{"cell_type":"code","source":["from pyspark.sql import functions as sf\nfrom pyspark.sql.functions import col, avg\nimport datetime"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\nquotechar = '\"'\nfile_location = 'FileStore/aries_accidents_2.csv'\nfile_type = \"csv\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .option(\"quotechar\", quotechar)\\\n  .load(file_location)\n\ndisplay(df.head(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>_c0</th><th>Blocks</th><th>speedlim</th><th>weekday</th><th>light</th><th>timecollide</th><th>weather</th><th>frequency</th><th>x1</th><th>x2</th><th>y1</th><th>y2</th><th>Xcentr</th><th>Ycentr</th></tr></thead><tbody><tr><td>0</td><td>474</td><td>40</td><td>TUESDAY</td><td>Dark (Not Lighted)</td><td>6-8 PM</td><td>Clear</td><td>1</td><td>37.74999999999999</td><td>37.78999999999999</td><td>-87.31999999999985</td><td>-87.27999999999984</td><td>37.769999999999996</td><td>-87.29999999999986</td></tr><tr><td>1</td><td>964</td><td>40</td><td>MONDAY</td><td>Daylight</td><td>6-8 PM</td><td>Clear</td><td>1</td><td>37.94999999999999</td><td>37.98999999999999</td><td>-85.7199999999996</td><td>-85.6799999999996</td><td>37.96999999999999</td><td>-85.6999999999996</td></tr><tr><td>2</td><td>1677</td><td>30</td><td>THURSDAY</td><td>Dark (Not Lighted)</td><td>6-8 PM</td><td>Cloudy</td><td>1</td><td>38.26999999999998</td><td>38.30999999999998</td><td>-85.99999999999964</td><td>-85.95999999999964</td><td>38.289999999999985</td><td>-85.97999999999965</td></tr><tr><td>3</td><td>1677</td><td>70</td><td>WEDNESDAY</td><td>Dark (Not Lighted)</td><td>4-6 AM</td><td>Clear</td><td>1</td><td>38.26999999999998</td><td>38.30999999999998</td><td>-85.99999999999964</td><td>-85.95999999999964</td><td>38.289999999999985</td><td>-85.97999999999965</td></tr><tr><td>4</td><td>1677</td><td>70</td><td>SUNDAY</td><td>Daylight</td><td>6-8 PM</td><td>Clear</td><td>1</td><td>38.26999999999998</td><td>38.30999999999998</td><td>-85.99999999999964</td><td>-85.95999999999964</td><td>38.289999999999985</td><td>-85.97999999999965</td></tr></tbody></table></div>"]}}],"execution_count":3},{"cell_type":"code","source":["#df.show()\ndf.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: 388098</div>"]}}],"execution_count":4},{"cell_type":"code","source":["df1 = df.select(df['Blocks'],df['speedlim'],df['weekday'],df['light'],df['timecollide'],df['weather'],df['frequency'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["temp_table_name = \"alldata\"\n\ndf1.createOrReplaceTempView(temp_table_name)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["%sql\nSelect count(1), avg(frequency) from alldata"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th><th>avg(CAST(frequency AS DOUBLE))</th></tr></thead><tbody><tr><td>388098</td><td>1.7579709248694917</td></tr></tbody></table></div>"]}}],"execution_count":7},{"cell_type":"code","source":["from pyspark.sql.types import IntegerType\ndf2 = df1.withColumn(\"frequency\", df1[\"frequency\"].cast(IntegerType()))\n#df2 = df2.withColumn(\"speedlim\", df2[\"speedlim\"].cast(IntegerType()))\n#df2 = df2.withColumn(\"Blocks\", df2[\"Blocks\"].cast(IntegerType()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["#df2.sort(col('frequency').desc()).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["#df2.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["temp_table_name = \"aries\"\n\ndf2.createOrReplaceTempView(temp_table_name)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["%sql\n\nSelect avg(frequency), count(1) From aries"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>avg(frequency)</th><th>count(1)</th></tr></thead><tbody><tr><td>1.7579709248694917</td><td>388098</td></tr></tbody></table></div>"]}}],"execution_count":12},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["from pyspark.ml.clustering import KMeans\nfrom pyspark.ml.evaluation import ClusteringEvaluator\nfrom pyspark.mllib.classification import LogisticRegressionModel,LogisticRegressionWithLBFGS, SVMWithSGD, SVMModel\nfrom pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD, LinearRegressionModel\n\n# LOAD PYSPARK LIBRARIES    \nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, VectorIndexer\nimport numpy as np"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["def indexing(df):\n\n  # INDEX AND ENCODE WEATHER\n  stringIndexer = StringIndexer(inputCol=\"weather\", outputCol=\"weatherIndex\")\n  model = stringIndexer.fit(df)\n  indexed = model.transform(df)\n  encoder = OneHotEncoder(dropLast=False, inputCol=\"weatherIndex\", outputCol=\"weatherVec\")\n  encoded1 = encoder.transform(indexed)\n\n  # INDEX AND ENCODE LIGHT CONDITION\n  stringIndexer = StringIndexer(inputCol=\"light\", outputCol=\"lightIndex\")\n  model = stringIndexer.fit(encoded1)\n  indexed = model.transform(encoded1)\n  encoder = OneHotEncoder(dropLast=False, inputCol=\"lightIndex\", outputCol=\"lightVec\")\n  encoded2 = encoder.transform(indexed)\n\n  # INDEX AND ENCODE WEEKDAY\n  stringIndexer = StringIndexer(inputCol=\"weekday\", outputCol=\"weekdayIndex\")\n  model = stringIndexer.fit(encoded2)\n  indexed = model.transform(encoded2)\n  encoder = OneHotEncoder(dropLast=False, inputCol=\"weekdayIndex\", outputCol=\"weekdayVec\")\n  encoded3 = encoder.transform(indexed)\n\n  # INDEX AND ENCODE TIME COLLIDE\n  stringIndexer = StringIndexer(inputCol=\"timecollide\", outputCol=\"timeIndex\")\n  model = stringIndexer.fit(encoded3)\n  indexed = model.transform(encoded3)\n  encoder = OneHotEncoder(dropLast=False, inputCol=\"timeIndex\", outputCol=\"timeVec\")\n  encoded4 = encoder.transform(indexed)\n  \n  # INDEX AND ENCODE BLOCKS\n  stringIndexer = StringIndexer(inputCol=\"Blocks\", outputCol=\"BlocksIndex\")\n  model = stringIndexer.fit(encoded4)\n  indexed = model.transform(encoded4)\n  encoder = OneHotEncoder(dropLast=False, inputCol=\"BlocksIndex\", outputCol=\"BlocksVec\")\n  encoded5 = encoder.transform(indexed)\n  \n  # INDEX AND ENCODE SPEED LIMIT\n  stringIndexer = StringIndexer(inputCol=\"speedlim\", outputCol=\"speedIndex\")\n  model = stringIndexer.fit(encoded5)\n  indexed = model.transform(encoded5)\n  encoder = OneHotEncoder(dropLast=False, inputCol=\"speedIndex\", outputCol=\"speedVec\")\n  encodedFinal = encoder.transform(indexed)\n  \n  return encodedFinal"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["encodedFinal = indexing(df2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["# FUNCTIONS FOR REGRESSION WITH TIP AMOUNT AS TARGET VARIABLE\n\n# ONE-HOT ENCODING OF CATEGORICAL TEXT FEATURES FOR INPUT INTO TREE-BASED MODELS\ndef parseRowIndexingRegression(line):\n    features = np.array([line.speedIndex,line.BlocksIndex,line.weekdayIndex,line.lightIndex\n                        ,line.timeIndex,line.weatherIndex])\n    label = np.array(float(line.frequency))\n    labPt = LabeledPoint(label, features)\n    return  labPt\n\n# INDEXING CATEGORICAL TEXT FEATURES FOR INPUT INTO LINEAR REGRESSION MODELS\ndef parseRowOneHotRegression(line):\n    features = np.concatenate((line.speedVec.toArray(),line.BlocksVec.toArray(),line.weekdayVec.toArray()\n                                        ,line.lightVec.toArray(),line.timeVec.toArray(),line.weatherVec.toArray()  ), axis =0)\n    labPt = LabeledPoint(line.frequency, features)\n    return  labPt"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# LOAD PYSPARK LIBRARIES\nfrom pyspark.sql.functions import rand\n\n# SPECIFY SAMPLING AND SPLITTING FRACTIONS\n#samplingFraction = 0.25;\ntrainingFraction = 0.75; testingFraction = (1-trainingFraction);\nseed = 1234;\n#encodedFinalSampled = encodedFinal.sample(False, samplingFraction, seed=seed)\n\n# SPLIT SAMPLED DATA-FRAME INTO TRAIN/TEST\n# INCLUDE RAND COLUMN FOR CREATING CROSS-VALIDATION FOLDS (FOR USE LATER IN AN ADVANCED TOPIC)\ndfTmpRand = encodedFinal.select(\"*\", rand(0).alias(\"rand\"));\ntrainData, testData = dfTmpRand.randomSplit([trainingFraction, testingFraction], seed=seed);"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"code","source":["trainData.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[23]: 290982</div>"]}}],"execution_count":20},{"cell_type":"code","source":["# FOR REGRESSION TRAINING AND TESTING\nindexedTRAINreg = trainData.rdd.map(parseRowIndexingRegression)\nindexedTESTreg = testData.rdd.map(parseRowIndexingRegression)\noneHotTRAINreg = trainData.rdd.map(parseRowOneHotRegression)\noneHotTESTreg = testData.rdd.map(parseRowOneHotRegression)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"code","source":["# FEATURE SCALING\n\n# RECORD START TIME\ntimestart = datetime.datetime.now()\n\n# LOAD PYSPARK LIBRARIES\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.linalg import Vectors\nfrom pyspark.mllib.feature import StandardScaler, StandardScalerModel\nfrom pyspark.mllib.util import MLUtils\n\n# SCALE VARIABLES FOR REGULARIZED LINEAR SGD ALGORITHM\n#label = oneHotTRAINreg.map(lambda x: x.label)\n#features = oneHotTRAINreg.map(lambda x: x.features)\n#scaler = StandardScaler(withMean=False, withStd=True).fit(features)\n#dataTMP = label.zip(scaler.transform(features.map(lambda x: Vectors.dense(x.toArray()))))\n#oneHotTRAINregScaled = dataTMP.map(lambda x: LabeledPoint(x[0], x[1]))\n\n#label = oneHotTESTreg.map(lambda x: x.label)\n#features = oneHotTESTreg.map(lambda x: x.features)\n#scaler = StandardScaler(withMean=False, withStd=True).fit(features)\n#dataTMP = label.zip(scaler.transform(features.map(lambda x: Vectors.dense(x.toArray()))))\n#oneHotTESTregScaled = dataTMP.map(lambda x: LabeledPoint(x[0], x[1]))\n\n# PRINT ELAPSED TIME\n#timeend = datetime.datetime.now()\n#timedelta = round((timeend-timestart).total_seconds(), 2) \n#print(\"Time taken to execute above cell: \" + str(timedelta) + \" seconds\"); "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["from pyspark.sql.functions import lit\nimport numpy as np\nimport pandas as pd\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"code","source":["#testPD.to_csv('/dbfs/FileStore/all_prediction_linear.csv')"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["indexedTRAINreg.take(10)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["#PREDICT TIP AMOUNTS USING GRADIENT BOOSTING TREES\n\n# RECORD START TIME\ntimestart= datetime.datetime.now()\n\n# LOAD PYSPARK LIBRARIES\nfrom pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\nfrom pyspark.mllib.util import MLUtils\n# LOAD LIBRARIES\nfrom pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD, LinearRegressionModel\nfrom pyspark.mllib.evaluation import RegressionMetrics\nfrom scipy import stats\n\n## TRAIN MODEL\ncategoricalFeaturesInfo={ 0:5, 1:9900, 2:7, 3:4, 4:12, 5:8}\ngbtModel = GradientBoostedTrees.trainRegressor(indexedTRAINreg, categoricalFeaturesInfo=categoricalFeaturesInfo, \n                                                numIterations=100, maxBins=9900, maxDepth = 6, learningRate=0.01)\n\n## EVALUATE A TEST DATA-SET\npredictions1 = gbtModel.predict(indexedTESTreg.map(lambda x: x.features))\npredictionAndLabels1 = indexedTESTreg.map(lambda lp: lp.label).zip(predictions1)\n\n# TEST METRICS\ntestMetrics1 = RegressionMetrics(predictionAndLabels1)\nprint(\"RMSE = %s\" % testMetrics1.rootMeanSquaredError)\nprint(\"R-sqr = %s\" % testMetrics1.r2)\n\n# SAVE MODEL IN BLOB\n#datestamp = unicode(datetime.datetime.now()).replace(' ','').replace(':','_');\n#btregressionfilename = \"GradientBoostingTreeRegression_\" + datestamp;\n#dirfilename = modelDir + btregressionfilename;\n#gbtModel.save(sc, dirfilename)\n\n# CONVERT RESULTS TO DF AND REGISTER TEMP TABLE\ntest_predictions = sqlContext.createDataFrame(predictionAndLabels1)\ntest_predictions.registerTempTable(\"tmp_results\");\n\n# PRINT ELAPSED TIME\ntimeend = datetime.datetime.now()\ntimedelta = round((timeend-timestart).total_seconds(), 2) \nprint(\"Time taken to execute above cell: \" + str(timedelta) + \" seconds\"); "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1476875476941161&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     15</span> categoricalFeaturesInfo<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">{</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">5</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">9900</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">7</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">4</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">4</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">12</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">5</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-cyan-fg\">8</span><span class=\"ansi-blue-fg\">}</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     16</span> gbtModel = GradientBoostedTrees.trainRegressor(indexedTRAINreg, categoricalFeaturesInfo=categoricalFeaturesInfo, \n<span class=\"ansi-green-fg\">---&gt; 17</span><span class=\"ansi-red-fg\">                                                 numIterations=100, maxBins=9900, maxDepth = 6, learningRate=0.01)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">     18</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     19</span> <span class=\"ansi-red-fg\">## EVALUATE A TEST DATA-SET</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/mllib/tree.py</span> in <span class=\"ansi-cyan-fg\">trainRegressor</span><span class=\"ansi-blue-fg\">(cls, data, categoricalFeaturesInfo, loss, numIterations, learningRate, maxDepth, maxBins)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    641</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">    642</span>         return cls._train(data, &#34;regression&#34;, categoricalFeaturesInfo,\n<span class=\"ansi-green-fg\">--&gt; 643</span><span class=\"ansi-red-fg\">                           loss, numIterations, learningRate, maxDepth, maxBins)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    644</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    645</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/mllib/tree.py</span> in <span class=\"ansi-cyan-fg\">_train</span><span class=\"ansi-blue-fg\">(cls, data, algo, categoricalFeaturesInfo, loss, numIterations, learningRate, maxDepth, maxBins)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    504</span>         <span class=\"ansi-green-fg\">assert</span> isinstance<span class=\"ansi-blue-fg\">(</span>first<span class=\"ansi-blue-fg\">,</span> LabeledPoint<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;the data should be RDD of LabeledPoint&#34;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    505</span>         model = callMLlibFunc(&#34;trainGradientBoostedTreesModel&#34;, data, algo, categoricalFeaturesInfo,\n<span class=\"ansi-green-fg\">--&gt; 506</span><span class=\"ansi-red-fg\">                               loss, numIterations, learningRate, maxDepth, maxBins)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    507</span>         <span class=\"ansi-green-fg\">return</span> GradientBoostedTreesModel<span class=\"ansi-blue-fg\">(</span>model<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    508</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/mllib/common.py</span> in <span class=\"ansi-cyan-fg\">callMLlibFunc</span><span class=\"ansi-blue-fg\">(name, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    128</span>     sc <span class=\"ansi-blue-fg\">=</span> SparkContext<span class=\"ansi-blue-fg\">.</span>getOrCreate<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    129</span>     api <span class=\"ansi-blue-fg\">=</span> getattr<span class=\"ansi-blue-fg\">(</span>sc<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>PythonMLLibAPI<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 130</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> callJavaFunc<span class=\"ansi-blue-fg\">(</span>sc<span class=\"ansi-blue-fg\">,</span> api<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    132</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/mllib/common.py</span> in <span class=\"ansi-cyan-fg\">callJavaFunc</span><span class=\"ansi-blue-fg\">(sc, func, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>     <span class=\"ansi-blue-fg\">&#34;&#34;&#34; Call Java Function &#34;&#34;&#34;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>     args <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>_py2java<span class=\"ansi-blue-fg\">(</span>sc<span class=\"ansi-blue-fg\">,</span> a<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> a <span class=\"ansi-green-fg\">in</span> args<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> _java2py<span class=\"ansi-blue-fg\">(</span>sc<span class=\"ansi-blue-fg\">,</span> func<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     61</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>             s <span class=\"ansi-blue-fg\">=</span> e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">.</span>toString<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o1569.trainGradientBoostedTreesModel.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 2499.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2499.0 (TID 18606, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 167779 ms\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2362)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2350)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2349)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2349)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1102)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1102)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1102)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2581)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2529)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2517)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:897)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2280)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2302)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2321)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2346)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:997)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:392)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:996)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:743)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:742)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:392)\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:742)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.findBestSplits(RandomForest.scala:583)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:204)\n\tat org.apache.spark.ml.regression.DecisionTreeRegressor$$anonfun$train$2.apply(DecisionTreeRegressor.scala:130)\n\tat org.apache.spark.ml.regression.DecisionTreeRegressor$$anonfun$train$2.apply(DecisionTreeRegressor.scala:125)\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$14.apply(Instrumentation.scala:277)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:277)\n\tat org.apache.spark.ml.regression.DecisionTreeRegressor.train(DecisionTreeRegressor.scala:125)\n\tat org.apache.spark.ml.tree.impl.GradientBoostedTrees$.boost(GradientBoostedTrees.scala:330)\n\tat org.apache.spark.ml.tree.impl.GradientBoostedTrees$.run(GradientBoostedTrees.scala:50)\n\tat org.apache.spark.mllib.tree.GradientBoostedTrees.run(GradientBoostedTrees.scala:70)\n\tat org.apache.spark.mllib.tree.GradientBoostedTrees$.train(GradientBoostedTrees.scala:135)\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainGradientBoostedTreesModel(PythonMLLibAPI.scala:816)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["## EVALUATE A TRAIN DATA-SET\npredictions1_train = gbtModel.predict(indexedTRAINreg.map(lambda x: x.features))\npredictionAndLabels1_train = indexedTRAINreg.map(lambda lp: lp.label).zip(predictions1_train)\n\n# TEST METRICS\ntestMetrics1_train = RegressionMetrics(predictionAndLabels1_train)\nprint(\"RMSE = %s\" % testMetrics1_train.rootMeanSquaredError)\nprint(\"R-sqr = %s\" % testMetrics1_train.r2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4391072026475157&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\">## EVALUATE A TRAIN DATA-SET</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>predictions1_train <span class=\"ansi-blue-fg\">=</span> gbtModel<span class=\"ansi-blue-fg\">.</span>predict<span class=\"ansi-blue-fg\">(</span>indexedTRAINreg<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span> x<span class=\"ansi-blue-fg\">.</span>features<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> predictionAndLabels1_train <span class=\"ansi-blue-fg\">=</span> indexedTRAINreg<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> lp<span class=\"ansi-blue-fg\">:</span> lp<span class=\"ansi-blue-fg\">.</span>label<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>zip<span class=\"ansi-blue-fg\">(</span>predictions1_train<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> <span class=\"ansi-red-fg\"># TEST METRICS</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;gbtModel&#39; is not defined</div>"]}}],"execution_count":30},{"cell_type":"code","source":["indexedTESTreg.first()"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["## EVALUATE A TEST DATA-SET\npredictions1 = gbtModel.predict(indexedTESTreg.map(lambda x: x.features))\npredictionAndLabels1 = indexedTESTreg.map(lambda lp: lp.label).zip(predictions1)\n\n# TEST METRICS\ntestMetrics1 = RegressionMetrics(predictionAndLabels1)\nprint(\"RMSE = %s\" % testMetrics1.rootMeanSquaredError)\nprint(\"R-sqr = %s\" % testMetrics1.r2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4391072026475159&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\">## EVALUATE A TEST DATA-SET</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>predictions1 <span class=\"ansi-blue-fg\">=</span> gbtModel<span class=\"ansi-blue-fg\">.</span>predict<span class=\"ansi-blue-fg\">(</span>indexedTESTreg<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span> x<span class=\"ansi-blue-fg\">.</span>features<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> predictionAndLabels1 <span class=\"ansi-blue-fg\">=</span> indexedTESTreg<span class=\"ansi-blue-fg\">.</span>map<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> lp<span class=\"ansi-blue-fg\">:</span> lp<span class=\"ansi-blue-fg\">.</span>label<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>zip<span class=\"ansi-blue-fg\">(</span>predictions1<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> <span class=\"ansi-red-fg\"># TEST METRICS</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;gbtModel&#39; is not defined</div>"]}}],"execution_count":32},{"cell_type":"code","source":["predictionAndLabels1.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4209863277113332&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>predictionAndLabels1<span class=\"ansi-blue-fg\">.</span>count<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;predictionAndLabels1&#39; is not defined</div>"]}}],"execution_count":33},{"cell_type":"code","source":["predicted_labelRDD = predictionAndLabels1.map(lambda x: x[1])\ncol_pred3 = predicted_labelRDD.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"code","source":["testData_1 = testData.select(testData['Blocks'],testData['speedlim'],testData['weekday'],testData['light'],testData['timecollide']\n                            ,testData['weather'])\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"code","source":["import folium"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":36},{"cell_type":"code","source":["testPD.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Blocks</th>\n      <th>speedlim</th>\n      <th>weekday</th>\n      <th>light</th>\n      <th>timecollide</th>\n      <th>weather</th>\n      <th>frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1002</td>\n      <td>30</td>\n      <td>FRIDAY</td>\n      <td>Daylight</td>\n      <td>2-4 PM</td>\n      <td>Clear</td>\n      <td>8.234894</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002</td>\n      <td>30</td>\n      <td>SATURDAY</td>\n      <td>Daylight</td>\n      <td>4-6 PM</td>\n      <td>Clear</td>\n      <td>5.415418</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1002</td>\n      <td>30</td>\n      <td>TUESDAY</td>\n      <td>Dark (Not Lighted)</td>\n      <td>10 PM - 12 AM</td>\n      <td>Clear</td>\n      <td>1.722055</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1010</td>\n      <td>30</td>\n      <td>FRIDAY</td>\n      <td>Dark (Not Lighted)</td>\n      <td>8-10 PM</td>\n      <td>Rain</td>\n      <td>0.984762</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1010</td>\n      <td>30</td>\n      <td>FRIDAY</td>\n      <td>Daylight</td>\n      <td>6-8 PM</td>\n      <td>Clear</td>\n      <td>2.255643</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":37},{"cell_type":"code","source":["temp_table_name_1 = \"mysubsetTable\"\n\ntestData_1.createOrReplaceTempView(temp_table_name_1)\n\ntemp_table_name = \"blockstable\"\n\ndf.createOrReplaceTempView(temp_table_name)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":38},{"cell_type":"code","source":["results = spark.sql(\"Select M.*,B.Xcentr,B.Ycentr from mysubsetTable M, blockstable B where M.BLocks = B.Blocks\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":39},{"cell_type":"code","source":["results.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: 32987336</div>"]}}],"execution_count":40},{"cell_type":"code","source":["preds = results\npreds_list = preds.collect()"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["import pandas as pd\npred_PD = pd.DataFrame(pred_list)\npred_PD['frequency'] = pd.Series(col_pred3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2022598516910135&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>pred_PD <span class=\"ansi-blue-fg\">=</span> pd<span class=\"ansi-blue-fg\">.</span>DataFrame<span class=\"ansi-blue-fg\">(</span>pred_list<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> pred_PD<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;frequency&#39;</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> pd<span class=\"ansi-blue-fg\">.</span>Series<span class=\"ansi-blue-fg\">(</span>col_pred3<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;pd&#39; is not defined</div>"]}}],"execution_count":42},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["## create test dataset for THURSDAY after 6 PM\nimport itertools\nblk_lst = []\nfor i in range(1,721):\n  blk_lst.append(i)\n  \na = [blk_lst,[30,40,50,60,70],['MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','SUNDAY'],['Dark (Not Lighted)','Dark (Lighted)','Daylight','Dawn/Dusk'],\n    ['12-2 AM','2-4 AM','4-6 AM','6-8 AM','8-10 AM','10 AM - 12 PM','12-2 PM','2-4 PM','4-6 PM','6-8 PM','8-10 PM','10 PM - 12 AM'],\n    ['Fog/Smoke/Smog','Cloudy','Clear','Blowing Sand/Soil/Snow','Severe Cross Wind','Snow','Rain','Sleet/Hail/Freezing Rain'],[0]]\n\nb = list(itertools.product(*a))\n\nfrom pyspark.sql import Row\nrdd1 = sc.parallelize(b)\nrow_rdd = rdd1.map(lambda p: Row(Blocks=p[0],speedlim=p[1],weekday=p[2],light=p[3],timecollide=p[4],weather=p[5],frequency=p[6]))\ntestDF=sqlContext.createDataFrame(row_rdd)"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["testDF1 = testDF.select(testDF['Blocks'],testDF['speedlim'],testDF['weekday'],testDF['light'],testDF['timecollide'],testDF['weather'],testDF['frequency'])\n#testDF1.show()"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["from pyspark.sql.types import StringType\ntestDF1 = testDF1.withColumn(\"Blocks\", testDF1[\"Blocks\"].cast(StringType()))\ntestDF1 = testDF1.withColumn(\"speedlim\", testDF1[\"speedlim\"].cast(StringType()))\ntestDF1 = testDF1.withColumn(\"frequency\", testDF1[\"frequency\"].cast(IntegerType()))"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["encodedTest = indexing(testDF1)"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["temp_table_name = \"testData\"\n\nencodedTest.createOrReplaceTempView(temp_table_name)"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["## TRI\nresult1 = spark.sql(\"Select * from testData where weekday = 'THURSDAY' and timecollide = '6-8 PM' and weather = 'Clear'  \")\nresult1.count()"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["encodedThursday = result1"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["#encodedThursday = indexing(testDF2)"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["# prepare data for thursday prediction\n#oneHotTHURSDAYreg = encodedThursday.rdd.map(parseRowOneHotRegression)\nindexedTHURSDAYreg = encodedThursday.rdd.map(parseRowIndexingRegression)"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":["indexedTHURSDAYreg.first()"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["\n# SCORE ON SCALED TEST DATA-SET & EVALUATE\n#predictionAndLabels1 = linearModel.predict(oneHotTHURSDAYreg.map(lambda x: x.features))\n\n#predictionAndLabels1 = indexedTHURSDAYreg.map(lambda lp: (float(gbtModel.predict(lp.features)), lp.label))\n\npredictions1 = gbtModel.predict(indexedTHURSDAYreg.map(lambda x: x.features))"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["predictions1.first()"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["## DOES NOT WORK, RAISE ERROR 'DIMENSION MISMATCH'\n\n#predicted_labelRDD1 = predictionAndLabels1.map(lambda x: x[0])\ncol_pred = predictions1.collect()\n\n\n\n#testPD1 = testDF1.toPandas()\n#testPD1['frequency'] = pd.Series(np.asarray(col_pred1))\n\n#testPD1.head()"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["max(col_pred)"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["import pandas as pd\ntestData_5 = encodedThursday.select(encodedThursday['Blocks'],encodedThursday['speedlim'],encodedThursday['weekday'],encodedThursday['light'],encodedThursday['timecollide']\n                            ,encodedThursday['weather'])\n\ntestPD1 = testData_5.toPandas()\ntestPD1['frequency'] = pd.Series(np.asarray(col_pred))"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["#testPD1['frequency'] = pd.Series(np.asarray(col_pred))"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":["testPD1"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"code","source":["testPD1[(testPD1.Blocks == '375')]"],"metadata":{},"outputs":[],"execution_count":70},{"cell_type":"code","source":["#testPD1.to_csv('/dbfs/FileStore/predictions.csv')"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"code","source":["#dbutils.fs.rm(\"FileStore/aries_accidents_1.csv\")"],"metadata":{},"outputs":[],"execution_count":72},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":73}],"metadata":{"name":"Test New CSV","notebookId":3285501123485399},"nbformat":4,"nbformat_minor":0}
